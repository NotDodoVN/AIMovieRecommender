{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70bcabb7-c237-4154-8c1b-ae6a006a98aa",
   "metadata": {},
   "source": [
    "Followed tutorial from https://www.stratascratch.com/blog/step-by-step-guide-to-building-content-based-filtering\n",
    "\n",
    "This movie recommender only use summary of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b965d8e6-06f8-4fa3-9959-17758275c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9aa563-f6e7-479e-9f01-112867bc87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a93d9b-1bbe-44ff-a314-377ad1563fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dokha\\AppData\\Local\\Temp\\ipykernel_4052\\1399212188.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movie_data = pd.read_csv('./the_movies_dataset/movies_metadata.csv')\n"
     ]
    }
   ],
   "source": [
    "#reading the file\n",
    "movie_data = pd.read_csv('./the_movies_dataset/movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8877563b-9881-45cb-85d2-eb6176ea5371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adult                        0\n",
       "belongs_to_collection    40972\n",
       "budget                       0\n",
       "genres                       0\n",
       "homepage                 37684\n",
       "id                           0\n",
       "imdb_id                     17\n",
       "original_language           11\n",
       "original_title               0\n",
       "overview                   954\n",
       "popularity                   5\n",
       "poster_path                386\n",
       "production_companies         3\n",
       "production_countries         3\n",
       "release_date                87\n",
       "revenue                      6\n",
       "runtime                    263\n",
       "spoken_languages             6\n",
       "status                      87\n",
       "tagline                  25054\n",
       "title                        6\n",
       "video                        6\n",
       "vote_average                 6\n",
       "vote_count                   6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7fa633-17bf-461b-9f58-98621744ac3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
       "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
       "       'popularity', 'poster_path', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
       "       'vote_average', 'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a8e4afc-28cf-4703-8638-e5d2567a629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adult                                                                False\n",
       "belongs_to_collection    {'id': 10194, 'name': 'Toy Story Collection', ...\n",
       "budget                                                            30000000\n",
       "genres                   [{'id': 16, 'name': 'Animation'}, {'id': 35, '...\n",
       "homepage                              http://toystory.disney.com/toy-story\n",
       "id                                                                     862\n",
       "imdb_id                                                          tt0114709\n",
       "original_language                                                       en\n",
       "original_title                                                   Toy Story\n",
       "overview                 Led by Woody, Andy's toys live happily in his ...\n",
       "popularity                                                       21.946943\n",
       "poster_path                               /rhIRbceoE9lR4veEXuwCC2wARtG.jpg\n",
       "production_companies        [{'name': 'Pixar Animation Studios', 'id': 3}]\n",
       "production_countries     [{'iso_3166_1': 'US', 'name': 'United States o...\n",
       "release_date                                                    1995-10-30\n",
       "revenue                                                        373554033.0\n",
       "runtime                                                               81.0\n",
       "spoken_languages                  [{'iso_639_1': 'en', 'name': 'English'}]\n",
       "status                                                            Released\n",
       "tagline                                                                NaN\n",
       "title                                                            Toy Story\n",
       "video                                                                False\n",
       "vote_average                                                           7.7\n",
       "vote_count                                                          5415.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec17ed8-e841-46ae-9e66-4fdedabe2139",
   "metadata": {},
   "source": [
    "I need genres (list[dict[]]) after conversion, popularity: float, runtime: float, spoken_languages: (list[dict[]]) -> after conversion, vote_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb7112f-455a-416d-9c2e-c32986c134d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie summary data, fill null value with empty string\n",
    "movie_summary = movie_data['overview'].fillna('')\n",
    "\n",
    "# Movie title data\n",
    "movie_title_data = movie_data['original_title']\n",
    "\n",
    "# Map movie title to its index\n",
    "movie_to_index = pd.Series(movie_data.index, index=movie_data['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9178f2d6-1e20-4b36-8526-e1ba729b0105",
   "metadata": {},
   "source": [
    "Convert movie_genres into list[dict[]] for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b1dc1d-cd3f-4e8f-89a8-8d035344e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45856c40-f832-4727-bd12-4c1b0c75543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Movie genre\n",
    "movie_genres = movie_data['genres'].fillna('[{}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75db440e-9148-45cc-b94e-038e6b0228e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_list_dic_into_actual(data):\n",
    "    for i in range(len(data)):\n",
    "        temp = data[i].strip('[').strip(']').replace(\"{\", \"\").replace(\"}\", \"\").split(',')\n",
    "    \n",
    "        convert_version = []\n",
    "        for _ in range(int(len(temp) // 2)):\n",
    "            convert_version.append(literal_eval(\"{\" + f\"{temp[0]}\" + \",\" +f\"{temp[1]}\" + \"}\"))\n",
    "            temp = temp[2:]\n",
    "        data[i] = convert_version\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ae167f-cc86-486f-9e39-cf404b00c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Movie language\n",
    "movie_spoken_language = movie_data['spoken_languages'].fillna('[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa76c40a-a767-4c92-913f-659592b463e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_string_list_dic_into_actual(movie_genres)\n",
    "convert_string_list_dic_into_actual(movie_spoken_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4be02015-e54f-4950-9a1b-88f9afcbec84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [{'iso_639_1': 'en', 'name': 'English'}]\n",
       "1        [{'iso_639_1': 'en', 'name': 'English'}, {'iso...\n",
       "2                 [{'iso_639_1': 'en', 'name': 'English'}]\n",
       "3                 [{'iso_639_1': 'en', 'name': 'English'}]\n",
       "4                 [{'iso_639_1': 'en', 'name': 'English'}]\n",
       "                               ...                        \n",
       "45461               [{'iso_639_1': 'fa', 'name': 'فارسی'}]\n",
       "45462                    [{'iso_639_1': 'tl', 'name': ''}]\n",
       "45463             [{'iso_639_1': 'en', 'name': 'English'}]\n",
       "45464                                                   []\n",
       "45465             [{'iso_639_1': 'en', 'name': 'English'}]\n",
       "Name: spoken_languages, Length: 45466, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_spoken_language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ac131-c47b-495d-b913-ff70100455d5",
   "metadata": {},
   "source": [
    "Let's just form a concatenated string of genres together so that I can use TF-IDF for values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f3eb27a-34ef-476d-9318-507ebf9f8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for concatenating string of genres or languages together\n",
    "def concate_string_list_dict_into_simple_string(data):\n",
    "    for index in range(len(data)):\n",
    "        temp_string = \"\"\n",
    "        for element in data.iloc[index]:\n",
    "            temp_string += f\"{element['name']} \"\n",
    "        data.iloc[index] = temp_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3021d78-32f3-4d1c-87cc-857a3186e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concate_string_list_dict_into_simple_string(movie_genres)\n",
    "concate_string_list_dict_into_simple_string(movie_spoken_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8b7916c-8aa8-43c3-8f10-440d6d1b50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will concatenate the three text-based reviews together to form a big variable so that we can use tfidf to produce item_feature matrix\n",
    "movie_str_criteria = dp(movie_genres)\n",
    "for index in range(len(movie_genres)):\n",
    "    movie_str_criteria[index] += movie_genres[index] + movie_spoken_language[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ad9404a-c080-4eb8-ac2c-859aee2beebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "movie_matrix = tfidf.fit_transform(movie_str_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3186b059-2988-4b86-bbd1-09a22427cdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45466, 120)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "244b4b54-e403-49cd-add6-7b22fe1e3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = movie_data[['runtime', 'popularity', 'vote_average']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc8728df-d3e3-4391-b66e-e0aabae16923",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = numerical_data.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8405738f-90c0-4a55-8f03-f9a8624097ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vote_average\n",
       "<class 'float'>    45466\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data['vote_average'].map(type).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b15f9eb-76f6-483a-8ad4-38a556406991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5efd86e-e0d1-43d3-8263-995ced2b7f57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Beware Of Frost Bites'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_4052\\251663339.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m scaler = StandardScaler()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m scaled_numerical_data = scaler.fit_transform(numerical_data)\n",
      "\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m     @wraps(f)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    318\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m             return_tuple = (\n",
      "\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    890\u001b[39m                 )\n\u001b[32m    891\u001b[39m \n\u001b[32m    892\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    903\u001b[39m             Fitted scaler.\n\u001b[32m    904\u001b[39m         \"\"\"\n\u001b[32m    905\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    906\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    939\u001b[39m         self : object\n\u001b[32m    940\u001b[39m             Fitted scaler.\n\u001b[32m    941\u001b[39m         \"\"\"\n\u001b[32m    942\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m         X = validate_data(\n\u001b[32m    944\u001b[39m             self,\n\u001b[32m    945\u001b[39m             X,\n\u001b[32m    946\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2950\u001b[39m             out = y\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2952\u001b[39m             out = X, y\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2957\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Beware Of Frost Bites'"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_numerical_data = scaler.fit_transform(numerical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab65763-622d-468a-89f1-d6dff99af73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Furious 7'\n",
    "idx = movie_to_index[title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62fae00-d073-46d8-a8f9-fd991437e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_movie_criteria = [movie_str_criteria[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cc94a-e4b9-4392-b206-1256c6bcf60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_movie_matrix = tfidf.transform(this_movie_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a3420c-d123-4730-a11d-9de60d8fc768",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_movie_matrix['runtime'] = movie_data[idx]['runtime']\n",
    "this_movie_matrix['popularity'] = movie_data[idx]['popularity']\n",
    "this_movie_matrix['vote_average'] = movie_data[idx]['vote_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e9e05-7508-4b1b-8407-22b0436ae51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = cosine_similarity(this_movie_matrix, movie_matrix).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33537cdd-d86c-4a57-acb5-793353a3f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words we can ignore are the ones in English\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "#result of training the tfidf model is that we will get the item-feature matrix.\n",
    "# movie_matrix= tfidf.fit_transform(movie_str_criteria)\n",
    "movie_matrix = tfidf.fit_transform(movie_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c6d96cf-e6f6-41c4-a520-f1ee037784e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'csr_matrix' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmovie_matrix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'csr_matrix' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "movie_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c19d8-87f4-43fc-b492-f5178c1122ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template \n",
    "# zz = movie_genres[0].strip('[').strip(']')\n",
    "# zz = zz.replace(\"{\", \"\").replace(\"}\", \"\").split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4dabe-8746-4938-b459-9071f5c4b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "50be0df0-af2f-4dad-bfc0-0bde658924dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65dcd40-874c-48a4-b028-daa6ebb7861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45466, 75827)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31eab79-1bdd-41aa-bdfb-1f49e296ed6a",
   "metadata": {},
   "source": [
    "#each movie is a vector of size 75827.\n",
    "We are using cosine to find similarity. (we could use Euclidean or dot product)\n",
    "\n",
    "Movie_summary is the key feature to determine which movie to recommend.\n",
    "Use TF-IDF to process text form of the movie summary into numerical so you can use cosine to find similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31472815-2ebd-4e17-b640-7a73c0c7ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Furious 7'\n",
    "idx = movie_to_index[title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3390a475-ecf7-419b-93f7-039b4a992dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_movie_summary = [movie_summary[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6486705-6d3d-407c-b2f8-8d1e13301ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_movie_matrix = tfidf.transform(this_movie_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd63f9b-f4fd-4373-84a9-00df143d1467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 75827)\n"
     ]
    }
   ],
   "source": [
    "print(this_movie_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "035c6f73-cdd5-4595-825e-c8a0f89426c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = cosine_similarity(this_movie_matrix, movie_matrix).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e80434cd-531d-4b4b-ab0e-1379d8855986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 45466 movies that we have computed their cosine_similarity\n",
    "# enumerate object looks like (n, value) where n is number of instances and value is result of cosine \n",
    "# similarity\n",
    "# reverse = True means sort in descing order\n",
    "# The integrity of the movie index in movie_indexes and movie_matrix are kept since we didn't change the\n",
    "# order in movie_matrix.\n",
    "sim_scores = sorted(enumerate(sim_scores), key= lambda i: i[1], reverse = True)\n",
    "\n",
    "# Fetch the top 10 recommended movies\n",
    "sim_scores = sim_scores[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78be7bcf-1aaf-4478-af6d-a10da954008f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4241, 0.2840828188953829), (20970, 0.2271265118239757), (40993, 0.21878271091976215), (17052, 0.1951022599960312), (29744, 0.17015267141759066), (12506, 0.17012985750201387), (44235, 0.15341519203643178), (34139, 0.15195480336228978), (3739, 0.1516962746883741), (13442, 0.1484508861061471)]\n"
     ]
    }
   ],
   "source": [
    "print(sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42139935-8365-41a2-aa5b-b7813894e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_indexes = [i[0] for i in sim_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12f4bf55-869c-4885-b484-5050ccfbb93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Fast and the Furious', 'Fast & Furious 6', 'Los violadores', 'Fast Five', 'Genius on Hold', 'Youth Without Youth', 'The Skydivers', 'Aenigma', 'The Cell', 'Urban Justice']\n"
     ]
    }
   ],
   "source": [
    "print([movie_title_data[i] for i in movie_indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3ab86197-37be-4624-91af-fb8785a57437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation(movie_title: str):\n",
    "    index = movie_to_index[movie_title]\n",
    "    this_movie_summary = [movie_summary[index]]\n",
    "    this_movie_matrix = tfidf.transform(this_movie_summary)\n",
    "    sim_scores = cosine_similarity(this_movie_matrix, movie_matrix).tolist()[0]\n",
    "    sim_scores = sorted(enumerate(sim_scores), key = lambda t: t[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    movie_titles = [movie_title_data[i] for i in movie_indices ]\n",
    "\n",
    "    return movie_titles\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "52454b42-f1af-4a8a-8938-0f2febcc9d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delta of Venus',\n",
       " 'Desirable',\n",
       " 'The Sun Also Rises',\n",
       " 'Chloe',\n",
       " 'White Nights',\n",
       " 'The Russia House',\n",
       " 'Anthropoid',\n",
       " 'The Wind and the Lion',\n",
       " 'Mille Mois',\n",
       " 'A Night in Casablanca']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendation(\"Casablanca\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
